{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trabalho3_fe_clf_hector_leonardo",
      "provenance": [],
      "mount_file_id": "1CO7R-n8FHjTLnR_x4ZyC81rSmdl88d2P",
      "authorship_tag": "ABX9TyNwpHFF0UlUe/QozHJQsxeM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mechhector/visao_computacional20212/blob/main/trabalho3/trabalho3_fe_clf_hector_leonardo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kova-jMlgAAC"
      },
      "source": [
        "## Instituto Federal de Educação, Ciência e Tecnologia do Ceará\n",
        "\n",
        "## Departamento de Indústria - *Campus* Fortaleza\n",
        "\n",
        "## Bacharelado em Egenharia de Mecatrônica\n",
        "\n",
        "## Visão Computacional - Prof. Pedro Pedrosa\n",
        "\n",
        "## Trabalho 3 - Extração de Atributos e Classificação\n",
        "\n",
        "### **Hector Leonardo Mota Moreira**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqEaqCcpg7yz"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wv0o_44Zf69o"
      },
      "source": [
        "def verifyNeigh(image, point, cn, chain_list):\n",
        "\n",
        "  '''\n",
        "  Verifies the neighborhood for 4- and 8-connectivity\n",
        "\n",
        "  [- 0 -]\n",
        "  [3 • 1]  4-connected reference\n",
        "  [- 2 -]\n",
        "\n",
        "  [7 0 1]\n",
        "  [6 • 2]  8-connected reference\n",
        "  [5 4 3]\n",
        "\n",
        "  '''\n",
        "\n",
        "  # 4-connected\n",
        "  if cn == 4:\n",
        "\n",
        "    #print(point)\n",
        "\n",
        "    # 0\n",
        "    if image[point[0]-1,point[1]] == 255:\n",
        "      image[point[0]-1,point[1]] = 0\n",
        "      #print('0')\n",
        "      chain_list.append(0)\n",
        "      return (point[0]-1,point[1])\n",
        "\n",
        "    # 1\n",
        "    elif image[point[0] , point[1]+1] == 255:\n",
        "      image[point[0] , point[1] + 1] = 0\n",
        "      #print('1')\n",
        "      chain_list.append(1)\n",
        "      return ([point[0] , point[1] + 1])\n",
        "\n",
        "    # 2\n",
        "    elif image[point[0]+1 , point[1]] == 255:\n",
        "      image[point[0]+1 , point[1]] = 0\n",
        "      #print('2')\n",
        "      chain_list.append(2)\n",
        "      return ([point[0]+1 , point[1]])\n",
        "\n",
        "    # 3\n",
        "    elif image[point[0] , point [1]-1] == 255:\n",
        "      image[point[0] , point[1]-1] = 0\n",
        "      #print('3')\n",
        "      chain_list.append(3)\n",
        "      return ([point[0] , point[1]-1])\n",
        "\n",
        "    else:\n",
        "      #print('none')\n",
        "      point = start_point\n",
        "\n",
        "  \n",
        "  # 8-connected     \n",
        "  if cn == 8: \n",
        "\n",
        "    print(point)\n",
        "\n",
        "     # 0\n",
        "    if image[point[0]-1,point[1]] == 255:\n",
        "      image[point[0]-1,point[1]] = 0\n",
        "      print('0')\n",
        "      chain_list.append(0)\n",
        "      return (point[0]-1,point[1])\n",
        "      \n",
        "    # 1\n",
        "    elif image[point[0]-1,point[1]+1] == 255:\n",
        "      image[point[0]-1,point[1]+1] = 0\n",
        "      print('1')\n",
        "      chain_list.append(1)\n",
        "      return (point[0]-1,point[1]+1)\n",
        "\n",
        "    # 2\n",
        "    elif image[point[0] , point[1]+1] == 255:\n",
        "      image[point[0] , point[1]+1] = 0\n",
        "      print('2')\n",
        "      chain_list.append(2)\n",
        "      return ([point[0] , point[1]+1])\n",
        "      \n",
        "    # 3\n",
        "    elif image[point[0]+1,point[1]+1] == 255:\n",
        "      image[point[0]+1,point[1]+1] = 0\n",
        "      print('3')\n",
        "      chain_list.append(3)\n",
        "      return (point[0]+1,point[1]+1)\n",
        "\n",
        "    # 4\n",
        "    elif image[point[0]+1 , point[1]] == 255:\n",
        "      image[point[0]+1 , point[1]] = 0\n",
        "      print('4')\n",
        "      chain_list.append(4)\n",
        "      return ([point[0]+1 , point[1]])\n",
        "\n",
        "    # 5\n",
        "    elif image[point[0]+1,point[1]-1] == 255:\n",
        "      image[point[0]+1,point[1]-1] = 0\n",
        "      print('5')\n",
        "      chain_list.append(5)\n",
        "      return (point[0]+1,point[1]-1)\n",
        "\n",
        "    # 6\n",
        "    elif image[point[0],point[1]-1] == 255:\n",
        "      image[point[0],point[1]-1] = 0\n",
        "      print('6')\n",
        "      chain_list.append(6)\n",
        "      return (point[0],point[1]-1)\n",
        "\n",
        "    # 7\n",
        "    elif image[point[0]-1 , point [1]-1] == 255:\n",
        "      image[point[0]-1 , point[1]-1] = 0\n",
        "      print('7')\n",
        "      chain_list.append(7)\n",
        "      return ([point[0]-1 , point[1]-1])\n",
        "\n",
        "    else:\n",
        "      print('none')\n",
        "      point = start_point\n",
        "      \n",
        "      \n",
        "  else:\n",
        "      return point\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dNIHwfahgWc"
      },
      "source": [
        "def chainCodeNormalization(chain_code_list):\n",
        "\n",
        "  '''\n",
        "\n",
        "  Normalizes the chain code into the shortest lenght \n",
        "\n",
        "  '''\n",
        "\n",
        "  normalized_list = []\n",
        "  \n",
        "  normalized_list.append(chain_code_list[0])\n",
        "\n",
        "  proportion_ratio = len(chain_code_list) / 21\n",
        "\n",
        "  sum = 0\n",
        "\n",
        "  holder = proportion_ratio\n",
        "\n",
        "  #print('proportion ratio: ',proportion_ratio)\n",
        "\n",
        "  while len(normalized_list) < 21:\n",
        "\n",
        "    sum = sum + int(holder)\n",
        "\n",
        "    #print(sum)\n",
        "\n",
        "    normalized_list.append(chain_code_list[sum])\n",
        "\n",
        "    pr_decimal = holder % 1\n",
        "\n",
        "    holder = proportion_ratio + pr_decimal\n",
        "\n",
        "\n",
        "\n",
        "  return normalized_list \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yJsY1N-h2Ub"
      },
      "source": [
        "def normalizeImage(v):\n",
        "  '''\n",
        "  Normalizes an image between 0 and 255\n",
        "  '''\n",
        "\n",
        "\n",
        "  v = (v - v.min()) / (v.max() - v.min())\n",
        "  result = (v * 255).astype(np.uint8)\n",
        "\n",
        "  #cv2_imshow(result)\n",
        "\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXl7d6FNi8gb"
      },
      "source": [
        "# HU Moments\n",
        "\n",
        "def HU_FE(image):\n",
        "        moments = cv2.moments(image.astype(np.float64))\n",
        "        return np.asarray(cv2.HuMoments(moments).flatten())\n",
        "\n",
        "# Gray Level Cooccurrency Matrix\n",
        "\n",
        "def GLCM_FE(image):\n",
        "        glcm = greycomatrix(image, [1], [0], 256, symmetric=True, normed=True)\n",
        "        xs = []\n",
        "        xs.append(greycoprops(glcm, 'dissimilarity')[0, 0])\n",
        "        xs.append(greycoprops(glcm, 'correlation')[0, 0])\n",
        "        xs.append(greycoprops(glcm, 'homogeneity')[0, 0])\n",
        "        xs.append(greycoprops(glcm, 'ASM')[0, 0])\n",
        "        xs.append(greycoprops(glcm, 'energy')[0, 0])\n",
        "        xs.append(greycoprops(glcm, 'correlation')[0, 0])\n",
        "        return np.asarray(xs);\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAAyjD9aiF3p"
      },
      "source": [
        "## Imports and data loading\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJXVQDREiLba",
        "outputId": "df41af91-fb11-4bd6-bd2f-40b1b531dcd9"
      },
      "source": [
        "import cv2 \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "\n",
        "from scipy import stats\n",
        "from scipy import ndimage\n",
        "\n",
        "from skimage.feature import greycomatrix, greycoprops, local_binary_pattern\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import datasets, svm, metrics\n",
        "from sklearn.model_selection import train_test_split, KFold, RepeatedKFold, cross_val_score, StratifiedShuffleSplit\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from skimage.feature import corner_fast, corner_peaks\n",
        "from sklearn.cluster import spectral_clustering\n",
        "from sklearn.feature_extraction import image\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Loading the dataset \n",
        "\n",
        "data_path = '/content/drive/MyDrive/DIP_2021.2/Trabalho 3 - DIP 2021.2/ocr_car_numbers_rotulado_1.txt'\n",
        "\n",
        "data = np.loadtxt(data_path)\n",
        "\n",
        "rows , cols = data.shape\n",
        "\n",
        "print(data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3352, 1226)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0sa9Jewj5dS"
      },
      "source": [
        "## FE Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrmSDyt3jWB8"
      },
      "source": [
        "# HU Moments Matrix\n",
        "\n",
        "hu_moments_matrix = np.zeros((rows, 7))\n",
        "\n",
        "for i in range(rows):\n",
        "  current_row = data[i]\n",
        "\n",
        "  current_row_image = current_row[0:cols-1].reshape(35,35) \n",
        "\n",
        "  current_row_normalized_image = normalizeImage(current_row_image) \n",
        "\n",
        "  hu_moments_current_row = HU_FE(current_row_normalized_image)\n",
        "\n",
        "  #cv2_imshow(current_row_normalized_image)\n",
        "\n",
        "  hu_moments_matrix[i] = hu_moments_current_row\n",
        "\n",
        "  #print(current_row[cols-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_erT8x0qkDbi"
      },
      "source": [
        "# GLCM Matrix\n",
        "\n",
        "glcm_matrix = np.zeros((rows, 6))\n",
        "\n",
        "for i in range(rows):\n",
        "  current_row = data[i]\n",
        "\n",
        "  current_row_image = current_row[0:cols-1].reshape(35,35) \n",
        "\n",
        "  current_row_normalized_image = normalizeImage(current_row_image) \n",
        "\n",
        "  glcm_current_row = GLCM_FE(current_row_normalized_image)\n",
        "\n",
        "  #cv2_imshow(current_row_normalized_image)\n",
        "\n",
        "  glcm_matrix[i] = glcm_current_row\n",
        "\n",
        "  #print(current_row[cols-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxFBzzjskHMa",
        "outputId": "aabf5904-ec41-4208-f6c0-f88c7748d4e1"
      },
      "source": [
        "# Chain List Matrix\n",
        "\n",
        "shortest_list = 21\n",
        "shortest_list_index = 0\n",
        "\n",
        "normalized_data_chain = np.zeros((rows, shortest_list))\n",
        "\n",
        "print(normalized_data_chain.shape)\n",
        "\n",
        "\n",
        "\n",
        "for i in range(rows):\n",
        "\n",
        "  # ============================= form an image ================================\n",
        " \n",
        "  current_row = data[i]\n",
        "\n",
        "  current_row_image = current_row[0:cols-1].reshape(35,35) \n",
        "\n",
        "  current_row_normalized_image = normalizeImage(current_row_image) \n",
        "\n",
        "  #print(current_row_normalized_image.shape)\n",
        "\n",
        "  filled_image = (ndimage.binary_fill_holes(current_row_normalized_image).astype(int))\n",
        "\n",
        "  normalized_filled_image = normalizeImage(filled_image)\n",
        "\n",
        "  \n",
        "  # ====================== dilation to get borders =============================\n",
        "\n",
        "  kernel = np.ones((3,3))\n",
        "  dilation = cv2.dilate(normalized_filled_image,kernel,iterations = 1)\n",
        "\n",
        "  border = dilation-normalized_filled_image \n",
        "\n",
        "  #cv2_imshow(border)\n",
        "\n",
        "\n",
        "  # ====================== identify the start point ============================\n",
        "\n",
        "  max_xy = np.where(border == 255)\n",
        "\n",
        "  #print(max_xy[0][0] , max_xy[1][0])\n",
        "\n",
        "  start_point = max_xy[0][0] , max_xy[1][0]\n",
        "\n",
        "\n",
        "  # ============================== chain list ==================================\n",
        "\n",
        "  chain_list = []\n",
        "\n",
        "  point = verifyNeigh(border, start_point, 4, chain_list)\n",
        "\n",
        "  while(point != start_point):\n",
        "\n",
        "    point = verifyNeigh(border, point, 4, chain_list)\n",
        "\n",
        "    #print(len(chain_list))\n",
        "\n",
        "  # ===================== to find the shortest list =============================\n",
        "\n",
        "  #if len(chain_list) < shortest_list:\n",
        "  # shortest_list = len(chain_list)\n",
        "  # shortest_list_index = i \n",
        "\n",
        "  # =========================== list normalization =============================    \n",
        "\n",
        "  if len(chain_list) > shortest_list:\n",
        "    normalized_list = chainCodeNormalization(chain_list) \n",
        "\n",
        "  normalized_data_chain[i] = normalized_list\n",
        "\n",
        "  \n",
        "print('Shortest list =', shortest_list)\n",
        "print('Shortest list index =', shortest_list_index, 'Target:', data[shortest_list_index][cols-1])\n",
        "print(len(chain_list))\n",
        "#print(normalized_list)\n",
        "print('\\n')\n",
        "print(normalized_data_chain, normalized_data_chain.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3352, 21)\n",
            "Shortest list = 21\n",
            "Shortest list index = 0 Target: 2.0\n",
            "76\n",
            "\n",
            "\n",
            "[[1. 1. 2. ... 3. 3. 1.]\n",
            " [1. 2. 2. ... 0. 0. 1.]\n",
            " [1. 1. 2. ... 0. 0. 0.]\n",
            " ...\n",
            " [1. 1. 1. ... 3. 3. 0.]\n",
            " [1. 1. 2. ... 3. 3. 0.]\n",
            " [1. 1. 2. ... 0. 0. 1.]] (3352, 21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kAWuRFGkWja"
      },
      "source": [
        "## Classifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaGXyw4DkaEJ",
        "outputId": "622b9108-d3e3-42d4-8bf5-058f0694b58b"
      },
      "source": [
        "# Targets vector\n",
        "\n",
        "targets = np.zeros((rows,))\n",
        "for k in range(rows):\n",
        "  targets[k] = data[k][cols-1]\n",
        "\n",
        "print(targets)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2. 6. 5. ... 7. 2. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVI2xZ-tkdFb"
      },
      "source": [
        "# Classifiers\n",
        "\n",
        "#X = normalized_data_chain\n",
        "X = hu_moments_matrix\n",
        "#X = glcm_matrix\n",
        "#X = binary_chain_data\n",
        "y = targets\n",
        "\n",
        "# SVM\n",
        "\n",
        "#clf = svm.SVC(gamma = 'auto')\n",
        "\n",
        "# SGDC Classifier\n",
        "\n",
        "#clf = make_pipeline(StandardScaler(), SGDClassifier(max_iter=15, tol=1e-2))\n",
        "\n",
        "# kNN Classifier\n",
        "\n",
        "#clf = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# MLP Classifier\n",
        "\n",
        "clf = MLPClassifier(random_state=1, max_iter=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaTNNrRIkfwb"
      },
      "source": [
        "# Setting the cross validation\n",
        "\n",
        "sss = StratifiedShuffleSplit(n_splits=10 , test_size=0.2)\n",
        "\n",
        "for train_index , test_index in sss.split(X,y):\n",
        "  X_train , X_test = X[train_index] , X[test_index]\n",
        "  y_train , y_test = y[train_index] , y[test_index]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7Z2xGEzkqpz"
      },
      "source": [
        "# Acc, std deviation and confusion matrix\n",
        "\n",
        "std = []\n",
        "\n",
        "mean_acc = 0\n",
        "\n",
        "c_matrix = 0\n",
        "\n",
        "for k, (train, test) in enumerate(sss.split(X, y)):\n",
        "    clf.fit(X[train], y[train])\n",
        "\n",
        "    predicted = clf.predict(X_test)\n",
        "\n",
        "    acc = metrics.accuracy_score(y_test, predicted)\n",
        "\n",
        "    std.append(acc)\n",
        "\n",
        "    mean_acc = mean_acc + acc\n",
        "\n",
        "    c_matrix = c_matrix + confusion_matrix(y_test, predicted)\n",
        "\n",
        "    #print(confusion_matrix(y_test, predicted))\n",
        "    #print(confusion_matrix(y_test, predicted).sum())\n",
        "\n",
        "    #print(\"Accuracy: \" f\"{metrics.accuracy_score(y_test, predicted)}\\n\")\n",
        "\n",
        "mean_c_matrix = c_matrix/10\n",
        "for i in range(mean_c_matrix.shape[0]):\n",
        "  for j in range(mean_c_matrix.shape[1]):\n",
        "    c_matrix[i][j] = round(c_matrix[i][j])    \n",
        "\n",
        "print('mean confusion matrix:') \n",
        "print(c_matrix/10) \n",
        "print('\\n')\n",
        "print('mean accuracy: ' , mean_acc/10) \n",
        "\n",
        "print('test samples: ' , c_matrix.sum()/10)\n",
        "\n",
        "print('std deviation: ' , np.asarray(std).std())\n",
        "print('\\n\\n')\n",
        "\n",
        "\n",
        "# To plot the confusion matrix\n",
        "\n",
        "plt.figure(figsize=(11,7))\n",
        "sn.set(font_scale=1.8) \n",
        "sn.heatmap(c_matrix/10, annot=True, annot_kws={\"size\": 18}) # font size\n",
        "plt.suptitle(\"Matriz de Confusão\")\n",
        "plt.xlabel(\"Predito\")\n",
        "plt.ylabel(\"Real\")\n",
        "plt.gcf().set_dpi(50)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuG1nISJk3Bk"
      },
      "source": [
        "# Metrics\n",
        "\n",
        "print(\n",
        "    f\"Classification report for classifier {clf}:\\n\"\n",
        "    f\"{metrics.classification_report(y_test, predicted)}\\n\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}