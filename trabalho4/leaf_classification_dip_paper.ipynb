{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "leaf_classification_dip_paper.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mechhector/visao_computacional20212/blob/main/trabalho4/leaf_classification_dip_paper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cl33e577OxQ"
      },
      "outputs": [],
      "source": [
        "# HU Moments\n",
        "\n",
        "def HU_FE(image):\n",
        "        moments = cv2.moments(image.astype(np.float64))\n",
        "        return np.asarray(cv2.HuMoments(moments).flatten())\n",
        "\n",
        "\n",
        "# LBP\n",
        "\n",
        "def LBP_FE(image):\n",
        "        lbp_image = local_binary_pattern(image, 256, 1, \"uniform\")\n",
        "        return np.histogram(lbp_image.ravel(), bins=256)\n",
        "        return (lbp_image)\n",
        "\n",
        "# Gray Level Cooccurrency Matrix\n",
        "\n",
        "def GLCM_FE(image):\n",
        "        glcm = greycomatrix(image, [1], [0], 256, symmetric=True, normed=True)\n",
        "        xs = []\n",
        "        xs.append(greycoprops(glcm, 'dissimilarity')[0, 0])\n",
        "        xs.append(greycoprops(glcm, 'correlation')[0, 0])\n",
        "        xs.append(greycoprops(glcm, 'homogeneity')[0, 0])\n",
        "        xs.append(greycoprops(glcm, 'ASM')[0, 0])\n",
        "        xs.append(greycoprops(glcm, 'energy')[0, 0])\n",
        "        return np.asarray(xs);\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalizeImage(v):\n",
        "  v = (v - v.min()) / (v.max() - v.min())\n",
        "  result = (v * 255).astype(np.uint8)\n",
        "\n",
        "  #cv2_imshow(result)\n",
        "\n",
        "  return result"
      ],
      "metadata": {
        "id": "u8NgFuP-8JgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "import time\n",
        "\n",
        "from scipy import stats\n",
        "from scipy import ndimage\n",
        "\n",
        "from skimage.feature import greycomatrix, greycoprops, local_binary_pattern\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import datasets, svm, metrics\n",
        "from sklearn.model_selection import train_test_split, KFold, RepeatedKFold, cross_val_score, StratifiedShuffleSplit\n",
        "from sklearn.feature_extraction import image\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "USZ0lKiK8LyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# features split\n",
        "\n",
        "dataset_features = np.zeros((340,7))\n",
        "\n",
        "for i in range(a.shape[0]):\n",
        "  \n",
        "  b = a[i]\n",
        "\n",
        "  dataset_features[i] = b[9:]\n",
        "\n",
        "print(dataset_features)\n",
        "\n",
        "#np.savetxt('texture_features.txt', dataset_features, delimiter=',')"
      ],
      "metadata": {
        "id": "5h9E3gCNiB4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset shape and texture features\n",
        "\n",
        "shape_features = np.loadtxt('/content/drive/MyDrive/Computer_Vision/Paper/shape_reatures.txt', delimiter = ',')\n",
        "\n",
        "texture_features = np.loadtxt('/content/drive/MyDrive/Computer_Vision/Paper/texture_features.txt', delimiter = ',')\n",
        "\n",
        "glcm_shape_features = np.loadtxt('/content/drive/MyDrive/Computer_Vision/Paper/merged_glcm_shape.txt', delimiter =',' )\n",
        "\n",
        "glcm_hu_features = np.loadtxt('/content/drive/MyDrive/Computer_Vision/Paper/glcm_hu_features.txt', delimiter = ',')\n",
        "\n",
        "dataset_features = np.loadtxt('/content/drive/MyDrive/Computer_Vision/Paper/dataset_features.txt', delimiter = ',')\n",
        "\n",
        "print(glcm_shape_features.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLrwSM8sETVf",
        "outputId": "bc47e7da-3f44-46c0-a479-45cb0392e53b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(340, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merged Leaf Matrix\n",
        "\n",
        "leaf_class = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36]\n",
        "numberOfSamples = [12,10,10,8,12,8,10,11,14,13,16,12,13,12,10,12,11,13,9,12,11,12,12,12,11,11,11,11,11,10]\n",
        "targets_vector = []\n",
        "\n",
        "merged_leaf_features = np.zeros((340,12))\n",
        "\n",
        "line_index = 0\n",
        "count = 1\n",
        "\n",
        "for i in leaf_class:\n",
        "  for j in range(numberOfSamples[leaf_class.index(i)]):\n",
        "  \n",
        "    #print(count)\n",
        "    #print(line_index)\n",
        "\n",
        "    hold_j = numberOfSamples[leaf_class.index(i)] + 1\n",
        "\n",
        "    \n",
        "    if i > 9 and j+1 > 9:\n",
        "\n",
        "      data_path = '/content/drive/MyDrive/Computer_Vision/Paper/merged_leaf/merged_leaf_C{}_EX{}.JPG'\n",
        "\n",
        "\n",
        "    elif i <= 9 and j+1 > 9:\n",
        "\n",
        "      data_path = '/content/drive/MyDrive/Computer_Vision/Paper/merged_leaf/merged_leaf_C0{}_EX{}.JPG'\n",
        "\n",
        "\n",
        "    elif i > 9 and j+1 <= 9:\n",
        "\n",
        "      data_path = '/content/drive/MyDrive/Computer_Vision/Paper/merged_leaf/merged_leaf_C{}_EX0{}.JPG'\n",
        "    \n",
        "    else:\n",
        "\n",
        "      data_path = '/content/drive/MyDrive/Computer_Vision/Paper/merged_leaf/merged_leaf_C0{}_EX0{}.JPG'\n",
        "\n",
        "\n",
        "    # Feature Extraction\n",
        "\n",
        "    #print(data_path.format(i,j+1))\n",
        "\n",
        "    if line_index == 45:\n",
        "      print(data_path.format(i,j+1))\n",
        "\n",
        "\n",
        "    leaf_image = cv2.imread(data_path.format(i,j+1),0)\n",
        "\n",
        "    if type(leaf_image) == None:\n",
        "      print(data_path.format(i,j+1))\n",
        "\n",
        "\n",
        "    glcm_leaf_image = GLCM_FE(leaf_image)\n",
        "\n",
        "    \n",
        "    hu_leaf_image = HU_FE(leaf_image)\n",
        "\n",
        "    merged_features = np.append(glcm_leaf_image,hu_leaf_image)\n",
        "\n",
        "    if line_index < 340:\n",
        "\n",
        "      merged_leaf_features[line_index] = merged_features\n",
        "\n",
        "    count = count + 1\n",
        "    \n",
        "    line_index = line_index + 1\n",
        "\n",
        "    targets_vector.append(i)\n",
        "\n",
        "\n",
        "print(merged_leaf_features.shape)\n",
        "\n",
        "print(targets_vector)\n",
        "\n",
        "np.savetxt('glcm_hu_features.txt', merged_leaf_features, delimiter=',')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzTsoD-jGkj7",
        "outputId": "570ec9c4-b2be-46ca-c9c3-5253a7f3b463"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Computer_Vision/Paper/merged_leaf/merged_leaf_C05_EX06.JPG\n",
            "(340, 12)\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "#main()\n",
        "\n",
        "data_list = [texture_features, shape_features, dataset_features, glcm_shape_features, glcm_hu_features]\n",
        "data_name =  ['texture_features', 'shape_features', 'dataset_features', 'glcm_shape_features', 'glcm_hu_features']\n",
        "hd = 0 \n",
        "#clf = KNeighborsClassifier(n_neighbors=5)\n",
        "#clf = MLPClassifier(random_state=1, max_iter=10000)\n",
        "#clf = tree.DecisionTreeClassifier()\n",
        "#clf = GaussianNB()\n",
        "\n",
        "for p in data_list: \n",
        "\n",
        "  X = p\n",
        "  y = np.asarray(targets_vector)\n",
        "\n",
        "  sss = StratifiedShuffleSplit(n_splits=10 , test_size=0.1)\n",
        "\n",
        "  for train_index , test_index in sss.split(X,y): \n",
        "    X_train , X_test = X[train_index] , X[test_index]\n",
        "    y_train , y_test = y[train_index] , y[test_index]\n",
        "\n",
        "\n",
        "\n",
        "    # Acc, std deviation and confusion matrix\n",
        "\n",
        "  std = []\n",
        "\n",
        "  mean_acc = 0\n",
        "\n",
        "  c_matrix = 0\n",
        "\n",
        "  for k, (train, test) in enumerate(sss.split(X, y)):\n",
        "      clf.fit(X[train], y[train])\n",
        "\n",
        "      predicted = clf.predict(X_test)\n",
        "\n",
        "      acc = metrics.accuracy_score(y_test, predicted)\n",
        "\n",
        "      std.append(acc)\n",
        "\n",
        "      mean_acc = mean_acc + acc\n",
        "\n",
        "      c_matrix = c_matrix + confusion_matrix(y_test, predicted)\n",
        "\n",
        "      #print(confusion_matrix(y_test, predicted))\n",
        "      #print(confusion_matrix(y_test, predicted).sum())\n",
        "\n",
        "      #print(\"Accuracy: \" f\"{metrics.accuracy_score(y_test, predicted)}\\n\")\n",
        "\n",
        "  mean_c_matrix = c_matrix/10\n",
        "  for i in range(mean_c_matrix.shape[0]):\n",
        "    for j in range(mean_c_matrix.shape[1]):\n",
        "      c_matrix[i][j] = round(c_matrix[i][j])    \n",
        "\n",
        "  #print('mean confusion matrix:') \n",
        "  #print(c_matrix/10) \n",
        "\n",
        "  \n",
        "  print(data_name[hd], str(clf))   \n",
        " \n",
        "  print('mean accuracy: ' , mean_acc/10) \n",
        "\n",
        "  #print('test samples: ' , c_matrix.sum()/10)\n",
        "\n",
        "  print('std deviation: ' , np.asarray(std).std())\n",
        "  print('\\n')\n",
        "  \n",
        "\n",
        "  hd = hd + 1\n",
        "\n",
        "# To plot the confusion matrix\n",
        "\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "'''\n",
        "plt.figure(figsize=(11,7))\n",
        "sn.set(font_scale=1.8) \n",
        "sn.heatmap(c_matrix/10, annot=True, annot_kws={\"size\": 18}) # font size\n",
        "plt.suptitle(\"Matriz de Confusão\")\n",
        "plt.xlabel(\"Predito\")\n",
        "plt.ylabel(\"Real\")\n",
        "plt.gcf().set_dpi(50)\n",
        "plt.show()\n",
        "'''"
      ],
      "metadata": {
        "id": "ikfHHZ3u8vt7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}